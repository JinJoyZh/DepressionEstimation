{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "34d8a9a6",
   "metadata": {},
   "source": [
    "# Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb7a84ae",
   "metadata": {},
   "source": [
    "## - dataset.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76af1da2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "580221c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DepressionDataset(Dataset):\n",
    "    '''create a training, develop, or test dataset\n",
    "       and load the participant features if it's called \n",
    "    '''\n",
    "    def __init__(self,\n",
    "                 root_dir,\n",
    "                 mode,\n",
    "                 transform=None):\n",
    "        super(DepressionDataset, self).__init__()\n",
    "        \n",
    "        # only train, develop, test dataset allow\n",
    "        assert mode in [\"train\", \"dev\", \"test\"],\\\n",
    "            \"Argument --mode could only be ['train', 'dev', 'test']\"\n",
    "        \n",
    "        self.mode = mode\n",
    "        self.root_dir = root_dir\n",
    "        self.transform = transform\n",
    "        self.train_data_path = os.path.join(self.root_dir, 'train_split_Depression_AVEC2017.csv')\n",
    "        self.dev_data_path = os.path.join(self.root_dir, 'dev_split_Depression_AVEC2017.csv')\n",
    "        self.test_data_path = os.path.join(self.root_dir, 'full_test_split.csv')\n",
    "        # load sent2vec model for converting text file to 2D array\n",
    "        self.sent2vec = SentenceTransformer('all-mpnet-base-v2')  # output dimension 768\n",
    "        \n",
    "        # load training data # 107 sessions\n",
    "        if self.mode == \"train\":\n",
    "            # pre-checking and cleaning the data\n",
    "            self.data_df = self.pre_check(pd.read_csv(self.train_data_path))\n",
    "            # store ground truth\n",
    "####################################################################################################\n",
    "#             self.patientIDs = self.data_df['Participant_ID'].to_numpy()\n",
    "            self.patientIDs = np.array([303,321,362,363,426]) # for debugging on my laptop\n",
    "####################################################################################################\n",
    "            self.phq_binay_gt = self.data_df['PHQ8_Binary'].to_numpy()\n",
    "            self.phq_score_gt = self.data_df['PHQ8_Score'].to_numpy()\n",
    "            self.gender_gt = self.data_df['Gender'].to_numpy()\n",
    "            self.phq_subscores_gt = self.data_df.iloc[:, 4:].to_numpy()\n",
    "        \n",
    "        # load development data # 35 sessions\n",
    "        if self.mode == \"dev\":\n",
    "            # pre-checking and cleaning the data\n",
    "            self.data_df = self.pre_check(pd.read_csv(self.dev_data_path))\n",
    "            # store ground truth\n",
    "            self.patientIDs = self.data_df['Participant_ID'].to_numpy()\n",
    "            self.phq_binay_gt = self.data_df['PHQ8_Binary'].to_numpy()\n",
    "            self.phq_score_gt = self.data_df['PHQ8_Score'].to_numpy()\n",
    "            self.gender_gt = self.data_df['Gender'].to_numpy()\n",
    "            self.phq_subscores_gt = self.data_df.iloc[:, 4:].to_numpy()\n",
    "        \n",
    "        # load test data # 47 sessions\n",
    "        if self.mode == \"test\":\n",
    "            # pre-checking and cleaning the data\n",
    "            self.data_df = self.pre_check(pd.read_csv(self.test_data_path))\n",
    "            # store ground truth\n",
    "            self.patientIDs = self.data_df['Participant_ID'].to_numpy()\n",
    "            self.phq_binay_gt = self.data_df['PHQ_Binary'].to_numpy()\n",
    "            self.phq_score_gt = self.data_df['PHQ_Score'].to_numpy()\n",
    "            self.gender_gt = self.data_df['Gender'].to_numpy()\n",
    "            self.phq_subscores_gt = None\n",
    "    \n",
    "    \n",
    "    def pre_check(self, data):\n",
    "        '''\n",
    "        Basic cleaning process to make sure no missing value\n",
    "        and that the sum of each PHQ subscore equals to PHQ score \n",
    "        Argument:\n",
    "            data: numpy array\n",
    "        Return:\n",
    "            data: numpy array with type \"int\"\n",
    "        '''\n",
    "        # make sure no NaN, Inf, -Inf\n",
    "        if data.isin([np.nan, np.inf, -np.inf]).any(1).sum():\n",
    "            print('Replacing NaN, Inf, or -Inf ...')\n",
    "            data = data.replace([np.inf, -np.inf, np.nan], 0).astype('int')\n",
    "        else: \n",
    "            data = data.astype('int')\n",
    "            \n",
    "        # compare the sum of each PHQ subscore to PHQ score\n",
    "        unequal = data.iloc[:, 4:].sum(axis=1) != data.iloc[:,2]\n",
    "        if unequal.any() and self.mode != 'test':\n",
    "            lines = np.where(unequal)\n",
    "            raise ValueError((\"The sum of each PHQ subscore at line {} \"\n",
    "                              \"is unequal to the PHQ score\").format(lines[0]))\n",
    "        \n",
    "        return data\n",
    "    \n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.patientIDs)\n",
    "    \n",
    "    \n",
    "    def __iter__(self):\n",
    "        return iter(self.patientIDs)\n",
    "    \n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        '''\n",
    "        Essentional function for creating dataset in PyTorch, which will automatically be\n",
    "        called in Dataloader and load all the extracted features of the patient in the Batch\n",
    "        based on the index of self.patientIDs\n",
    "        Argument:\n",
    "            idx: int, index of the patient ID in self.patientIDs\n",
    "        Return:\n",
    "            session: dict, contains all the extracted features and ground truth of a patient/session \n",
    "        '''\n",
    "        if torch.is_tensor(idx):\n",
    "            idx = idx.tolist()\n",
    "        \n",
    "        # get the patient session path\n",
    "        session_num = self.patientIDs[idx]\n",
    "        session_path = os.path.join(self.root_dir, '{}_P'.format(session_num))\n",
    "        \n",
    "        # TODO: if other feature is needed, add more in the following part...\n",
    "        \n",
    "        # get text path\n",
    "        text_path = os.path.join(session_path, '{}_TRANSCRIPT.csv'.format(session_num))\n",
    "        \n",
    "        # text feature\n",
    "        self.text_feature = self.load_sent2vec(text_path, speaker='Participant')\n",
    "        sentence_embedding = self.text_feature['sentence_embeddings']\n",
    "        \n",
    "        # summary\n",
    "        session = {'patientID': session_num,\n",
    "                   'session_path': session_path,\n",
    "                   'sentence_embeddings': sentence_embedding, \n",
    "                   'phq_score_gt': self.phq_score_gt[idx], \n",
    "                   'phq_binay_gt': self.phq_binay_gt[idx],\n",
    "                   'phq_subscores_gt': self.phq_subscores_gt[idx],\n",
    "                   'gender_gt': self.gender_gt[idx]}\n",
    "        \n",
    "        if self.transform:\n",
    "            session = self.transform(session)\n",
    "        \n",
    "        return session\n",
    "    \n",
    "    \n",
    "    def load_sent2vec(self, text_path, speaker='Participant'):\n",
    "        '''\n",
    "        load the text file and use sent2vec model from SentenceTransformer\n",
    "        for sentence embeddings, which generates 2D array\n",
    "        Arguments:\n",
    "            text_path: string, absolute path to transcipt file\n",
    "            speaker: certain string, which transcript of the speaker to load\n",
    "        Return:\n",
    "            text_feature: dict, contain converted embedding vectors, sentences, etc.\n",
    "        '''\n",
    "        \n",
    "        # only 'Ellie', 'Participant', 'both' are allow\n",
    "        assert speaker in ['Ellie', 'Participant', 'both'],\\\n",
    "            \"Argument --speaker could only be ['Ellie', 'Participant', 'both']\"\n",
    "        \n",
    "        text_file = pd.read_csv(text_path)\n",
    "        # tokenize the text file, filter out all \\t space and unnecessary columns such as time, participent \n",
    "        tokenized_words = self.tokenize_corpus(text_file.values.tolist()[i][0] for i in range(text_file.shape[0]))\n",
    "        \n",
    "        sentences = []\n",
    "        sentences_idx = []\n",
    "        \n",
    "        if speaker == 'Ellie':\n",
    "            for idx, sentence in enumerate(tokenized_words):\n",
    "                if sentence[2] == 'Ellie':\n",
    "                    sentences.append(sentence[3:])\n",
    "                    sentences_idx.append(idx)\n",
    "        elif speaker == 'Participant':\n",
    "            for idx, sentence in enumerate(tokenized_words):\n",
    "                if sentence[2] == 'Participant':\n",
    "                    sentences.append(sentence[3:])\n",
    "                    sentences_idx.append(idx)\n",
    "                    \n",
    "        else: # speaker == 'both'\n",
    "            sentences = [tokenized_words[i][3:] for i in range(len(tokenized_words))]\n",
    "            sentences_idx = list(range(len(tokenized_words)))\n",
    "    \n",
    "        # recombine 2D list of words into 1D list of sentence\n",
    "        final_sentences = [\" \".join(sentences[i]).lower() for i in range(len(sentences))]\n",
    "        # convert sentence to vector with SentenceTransformer pretrained model\n",
    "        sentence_embeddings = self.sent2vec.encode(final_sentences)\n",
    "        \n",
    "        # summary\n",
    "        text_feature = {'speaker': speaker,\n",
    "                        'sentence_embeddings': sentence_embeddings,\n",
    "                        'sentences': final_sentences, \n",
    "                        'indices': sentences_idx}\n",
    "        \n",
    "        return text_feature\n",
    "     \n",
    "        \n",
    "    def tokenize_corpus(self, corpus):\n",
    "        '''tokenzie a given list of string into list of words\n",
    "        Argument:\n",
    "            corpus: 1D list of string, each element is a sting of sentence\n",
    "        Return:\n",
    "            tokens: 2D list of string, each raw is a list of words splitted from sentence \n",
    "        '''\n",
    "        tokens = [x.split() for x in corpus]\n",
    "        return tokens\n",
    "\n",
    "    \n",
    "class Padding(object):\n",
    "    ''' pad zero to each feature matrix so that they all have the same size '''\n",
    "    def __init__(self, text_output_size=(386, 768)):\n",
    "        super(Padding, self).__init__()\n",
    "        '''\n",
    "        Each output size could be 'int' or 'tuple'. \n",
    "        Integer would be the number of desired rows\n",
    "        and Tuple would be the desired 2D array size.\n",
    "        \n",
    "        Here is recommended to keep the number of columns \n",
    "        as they are and only set the number of rows with int\n",
    "        \n",
    "        To find the maximum length of rows, please use the \n",
    "        'find_max_length' function in utils to search through. \n",
    "        \n",
    "        The value 389 are the maximum length in our case.\n",
    "        '''\n",
    "        assert isinstance(text_output_size, (int, tuple))\n",
    "        self.text_output_size = text_output_size\n",
    "    \n",
    "    \n",
    "    def __call__(self, session):\n",
    "        sentence_embeddings = session['sentence_embeddings']\n",
    "        \n",
    "        # text padding\n",
    "        if isinstance(self.text_output_size, int):\n",
    "            shape = sentence_embeddings.shape\n",
    "            assert self.text_output_size >= shape[0],\\\n",
    "                \"audio output size should be bigger than {}\".format(shape[0])\n",
    "            padded_text = np.zeros((self.text_output_size, shape[1]))\n",
    "            padded_text[:shape[0],:shape[1]] = sentence_embeddings\n",
    "        else:\n",
    "            shape = sentence_embeddings.shape\n",
    "            assert self.text_output_size[0] >= shape[0] and self.text_output_size[1] >= shape[1],\\\n",
    "                \"audio output size should be bigger than {}\".format(shape)\n",
    "            padded_text = np.zeros(self.text_output_size)\n",
    "            padded_text[:shape[0],:shape[1]] = sentence_embeddings\n",
    "        \n",
    "        # summary\n",
    "        padded_session = {'patientID': session['patientID'],\n",
    "                          'session_path': session['session_path'],\n",
    "                          'sentence_embeddings': padded_text, \n",
    "                          'phq_score_gt': session['phq_score_gt'], \n",
    "                          'phq_binay_gt': session['phq_binay_gt'],\n",
    "                          'phq_subscores_gt': session['phq_subscores_gt'],\n",
    "                          'gender_gt': session['gender_gt']}\n",
    "        \n",
    "        return padded_session\n",
    "    \n",
    "\n",
    "class ToTensor(object):\n",
    "    \"\"\"Convert ndarrays in sample to Tensors or np.int to torch.tensor.\"\"\"\n",
    "    \n",
    "    def __call__(self, session):\n",
    "        sentence_embeddings = session['sentence_embeddings']\n",
    "        \n",
    "        converted_session = {'patientID': session['patientID'],\n",
    "                             'session_path': session['session_path'],\n",
    "                             'sentence_embeddings': torch.from_numpy(session['sentence_embeddings']), \n",
    "                             'phq_score_gt': torch.tensor(session['phq_score_gt']), \n",
    "                             'phq_binay_gt': torch.tensor(session['phq_binay_gt']),\n",
    "                             'phq_subscores_gt': session['phq_subscores_gt'],\n",
    "                             'gender_gt': torch.tensor(session['gender_gt'])}\n",
    "        \n",
    "        return converted_session"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "966af1ce",
   "metadata": {},
   "source": [
    "## - utils.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9d5961f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# from skimage import io, transform\n",
    "# from mpl_toolkits.mplot3d import Axes3D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5d766f74",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data-related functions\n",
    "\n",
    "def minmax_scaler(data):\n",
    "    '''recale the data, which is a 2D matrix, to 0-1'''\n",
    "    return (data - data.min(axis=1)[:,np.newaxis])/(data.max(axis=1) - data.min(axis=1))[:, np.newaxis]\n",
    "\n",
    "\n",
    "def cosine_similarity(u, v):\n",
    "    '''Calculate the similarity between 1D arrays'''\n",
    "    return np.dot(u, v) / (np.linalg.norm(u) * np.linalg.norm(v))\n",
    "\n",
    "\n",
    "def similarity_matrix(array):\n",
    "    '''Calculate the similarity matrix by given a 2D array'''\n",
    "    shape = array.shape\n",
    "    similarity = np.zeros((shape[0],shape[0]))\n",
    "\n",
    "    for i in range(shape[0]):\n",
    "        for k in range(shape[0]):\n",
    "            similarity[i][k] = cosine_similarity(array[i], array[k])\n",
    "\n",
    "    return similarity\n",
    "\n",
    "\n",
    "def load_text_file(text_path, speaker='Participant'):\n",
    "    '''load transcript file and extract the text of the given speaker'''\n",
    "    \n",
    "    def tokenize_corpus(corpus):\n",
    "        '''tokenzie a given list of string into list of words'''\n",
    "        tokens = [x.split() for x in corpus]\n",
    "        return tokens\n",
    "\n",
    "    # only 'Ellie', 'Participant', 'both' are allow\n",
    "    assert speaker in ['Ellie', 'Participant', 'both'],\\\n",
    "        \"Argument --speaker could only be ['Ellie', 'Participant', 'both']\"\n",
    "\n",
    "    text_file = pd.read_csv(text_path)\n",
    "    # tokenize the text file, filter out all \\t space and unnecessary columns such as time, participent \n",
    "    tokenized_words = tokenize_corpus(text_file.values.tolist()[i][0] for i in range(text_file.shape[0]))\n",
    "\n",
    "    sentences = []\n",
    "    sentences_idx = []\n",
    "\n",
    "    if speaker == 'Ellie':\n",
    "        for idx, sentence in enumerate(tokenized_words):\n",
    "            if sentence[2] == 'Ellie':\n",
    "                sentences.append(sentence[3:])\n",
    "                sentences_idx.append(idx)\n",
    "    elif speaker == 'Participant':\n",
    "        for idx, sentence in enumerate(tokenized_words):\n",
    "            if sentence[2] == 'Participant':\n",
    "                sentences.append(sentence[3:])\n",
    "                sentences_idx.append(idx)\n",
    "\n",
    "    else: # speaker == 'both'\n",
    "        sentences = [tokenized_words[i][3:] for i in range(len(tokenized_words))]\n",
    "        sentences_idx = list(range(len(tokenized_words)))\n",
    "\n",
    "    # recombine 2D list of words into 1D list of sentence\n",
    "    final_sentences = [\" \".join(sentences[i]).lower() for i in range(len(sentences))]\n",
    "\n",
    "    return final_sentences\n",
    "\n",
    "\n",
    "def find_max_length(root_dir):\n",
    "    '''find out the maximum lenghth of each features among all patients'''\n",
    "\n",
    "    # initialize each value\n",
    "    max_length = {'landmarks': 0, \n",
    "                  'gaze_samples': 0, \n",
    "                  'sentences': 0}\n",
    "\n",
    "    for name in os.listdir(root_dir):\n",
    "        name_path = os.path.join(root_dir, name)\n",
    "        if os.path.isdir(name_path) and name.endswith('_P'):\n",
    "            session = name.split('_')[0]\n",
    "            print('searching through patient {} ...'.format(session))\n",
    "\n",
    "            facial_landmarks_path = os.path.join(name_path, '{}_CLNF_features3D.txt'.format(session))\n",
    "            gaze_direction_path = os.path.join(name_path, '{}_CLNF_gaze.txt'.format(session))\n",
    "            text_path = os.path.join(name_path, '{}_TRANSCRIPT.csv'.format(session))\n",
    "\n",
    "            facial_landmarks = pd.read_csv(facial_landmarks_path)\n",
    "            if len(facial_landmarks) > max_length['landmarks']:\n",
    "                max_length['landmarks'] = len(facial_landmarks)\n",
    "\n",
    "            gaze_direction = pd.read_csv(gaze_direction_path)\n",
    "            if len(gaze_direction) > max_length['gaze_samples']:\n",
    "                max_length['gaze_samples'] = len(gaze_direction)\n",
    "\n",
    "            sentences = load_text_file(text_path, speaker='Participant')\n",
    "            if len(sentences) > max_length['sentences']:\n",
    "                max_length['sentences'] = len(sentences)\n",
    "\n",
    "    if max_length['gaze_samples'] != max_length['landmarks']:\n",
    "        max_length['gaze_samples'] = max_length['landmarks']\n",
    "\n",
    "    return max_length\n",
    "\n",
    "\n",
    "def show_text_correlation(text_feature, start_sent, sent_len):\n",
    "    \"\"\"Show the correlation between each sentence.\n",
    "    Arguments:\n",
    "        text_feature: dict, one attribute of DepressionDataset, which\n",
    "                      includes converted sentence embedding vectors (2D numpy.ndarray)\n",
    "        start_sent: int, start index of the sentence you want\n",
    "        sent_len: int, number of sentence you want to compare \n",
    "                  (size of correlation matrix)\n",
    "    Return:\n",
    "        plot the correlation matrix between sentences\n",
    "    \"\"\"\n",
    "    # calculate correlation matrix\n",
    "    correlation = np.corrcoef(text_feature['sentence_embeddings'][int(start_sent):int(start_sent+sent_len)])\n",
    "    plt.figure(figsize=(12,12))\n",
    "    # plot heatmap\n",
    "    heatmap = sns.heatmap(correlation, annot=True,  fmt='.2g')  # cbar_kws={'label': 'correlation'}\n",
    "    # set scale label\n",
    "    heatmap.set_xticklabels(text_feature['indices'][int(start_sent):int(start_sent+sent_len)]) # rotation=-30\n",
    "    heatmap.set_yticklabels(text_feature['indices'][int(start_sent):int(start_sent+sent_len)], rotation=0)\n",
    "    # set label\n",
    "    plt.xlabel(\"sentence number in conversation\")\n",
    "    plt.ylabel(\"sentence number in conversation\") \n",
    "    plt.show()\n",
    "\n",
    "\n",
    "def show_similarity_matrix(text_feature, start_sent, sent_len):\n",
    "    '''plot the result of similarity matrix as heatmap'''\n",
    "    # calculate similarity\n",
    "    similarity = similarity_matrix(text_feature['sentence_embeddings'][int(start_sent):int(start_sent+sent_len)])\n",
    "    # plot heatmap\n",
    "    plt.figure(figsize=(16,16))\n",
    "    heatmap = sns.heatmap(similarity, annot=True,  fmt='.2g')  # cbar_kws={'label': 'correlation'}\n",
    "    # set scale label\n",
    "    heatmap.set_xticklabels(text_feature['indices'][int(start_sent):int(start_sent+sent_len)]) # rotation=-30\n",
    "    heatmap.set_yticklabels(text_feature['indices'][int(start_sent):int(start_sent+sent_len)], rotation=0)\n",
    "    # set label\n",
    "    plt.xlabel(\"sentence number in conversation\")\n",
    "    plt.ylabel(\"sentence number in conversation\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1c9c4c7",
   "metadata": {},
   "source": [
    "##### test block"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "ff0c7669",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch number:  0 , sentence embeddings:  torch.Size([2, 386, 768])\n",
      "=================================\n",
      "Batch number:  1 , sentence embeddings:  torch.Size([2, 386, 768])\n",
      "=================================\n",
      "Batch number:  2 , sentence embeddings:  torch.Size([1, 386, 768])\n",
      "=================================\n"
     ]
    }
   ],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "from torchvision import transforms\n",
    "\n",
    "# test 3: try to load the dataset with DataLoader\n",
    "transformed_dataset = DepressionDataset(os.path.join(os.getcwd(), 'DAIC-WOZ Dataset'), 'train',\n",
    "                                        transform=transforms.Compose([Padding(), ToTensor()]))\n",
    "# create dataloader\n",
    "dataloader = DataLoader(transformed_dataset, \n",
    "                        batch_size=2,\n",
    "                        shuffle=False, \n",
    "                        num_workers=0)\n",
    "# iterate through batches\n",
    "for i_batch, sample_batched in enumerate(dataloader):\n",
    "    print('Batch number: ', i_batch, ', sentence embeddings: ', sample_batched['sentence_embeddings'].size())\n",
    "    print('=================================')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16827bf5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67529010",
   "metadata": {},
   "outputs": [],
   "source": [
    "show_similarity_matrix(getattr(transformed_dataset, 'text_feature'), 10, 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ce13efd",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "872d04e2",
   "metadata": {},
   "source": [
    "## - transformer.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "030a9f17",
   "metadata": {},
   "outputs": [],
   "source": [
    "# d_model = emsize = embedding_dim\n",
    "# d_hid = d_hid = feedforward_dim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ce99c910",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "from typing import Tuple\n",
    "\n",
    "import torch \n",
    "from torch import nn, Tensor\n",
    "from torch.nn import TransformerEncoder, TransformerEncoderLayer\n",
    "# from torch.utils.data import dataset\n",
    "# import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "3f34633c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PositionalEncoding(nn.Module):\n",
    "\n",
    "    def __init__(self, embedding_dim: int, dropout: float = 0.1, max_len: int = 500):\n",
    "        super(PositionalEncoding, self).__init__()\n",
    "        \n",
    "        self.dropout = nn.Dropout(p=dropout)\n",
    "        \n",
    "        position = torch.arange(max_len).unsqueeze(1)  # shape: max_len x 1\n",
    "        div_term = torch.exp(torch.arange(0, embedding_dim, 2) * (-math.log(10000.0) / embedding_dim)) # shape, (embedding_dim-1)//2 + 1\n",
    "        pe = torch.zeros(max_len, 1, embedding_dim)  # shape: max_len x 1 x embedding_dim\n",
    "        pe[:, 0, 0::2] = torch.sin(position * div_term)\n",
    "        pe[:, 0, 1::2] = torch.cos(position * div_term)\n",
    "        self.register_buffer('pe', pe)\n",
    "\n",
    "    def forward(self, x: Tensor) -> Tensor:\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            x: Tensor, shape [seq_len, batch_size, embedding_dim]\n",
    "        \"\"\"\n",
    "        x = x + self.pe[:x.size(0)]\n",
    "        return self.dropout(x)\n",
    "\n",
    "    \n",
    "class TransformerModel(nn.Module):\n",
    "    \n",
    "    def __init__(self,  \n",
    "                 input_embedding_dim: int,\n",
    "                 output_feature_dim:int,\n",
    "                 nhead: int, \n",
    "                 feedforward_dim: int,\n",
    "                 nlayers: int,\n",
    "                 dropout: float = 0.5):  # ntoken\n",
    "        super(TransformerModel, self).__init__()\n",
    "        \n",
    "        self.model_type = 'Transformer'\n",
    "        self.input_embedding_dim = input_embedding_dim\n",
    "        self.output_feature_dim = output_feature_dim\n",
    "\n",
    "        self.pos_encoder = PositionalEncoding(input_embedding_dim, dropout)\n",
    "        encoder_layers = TransformerEncoderLayer(input_embedding_dim, nhead, feedforward_dim, dropout)\n",
    "        self.transformer_encoder = TransformerEncoder(encoder_layers, nlayers)\n",
    "        \n",
    "##################################################################\n",
    "        self.mlp_head = nn.Linear(input_embedding_dim, output_feature_dim)\n",
    "\n",
    "#         self.mlp_head = nn.Sequential(\n",
    "#             nn.LayerNorm(input_embedding_dim),\n",
    "#             nn.Linear(input_embedding_dim, output_feature_dim)\n",
    "#         )\n",
    "#         self.decoder = nn.Linear(embedding_dim, ntoken) # ntoken = output dimension, set it yourself\n",
    "#         self.encoder = nn.Embedding(ntoken, embedding_dim)\n",
    "##################################################################\n",
    "        \n",
    "        self.init_weights()\n",
    "    \n",
    "    \n",
    "    def init_weights(self) -> None:\n",
    "        init_range = 0.1\n",
    "        self.mlp_head.bias.data.zero_()\n",
    "        self.mlp_head.weight.data.uniform_(-init_range, init_range)\n",
    "#         self.encoder.weight.data.uniform_(-init_range, init_range)\n",
    "        \n",
    "    def forward(self, src: Tensor, src_mask: Tensor) -> Tensor:\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            src: Tensor, shape [seq_len, batch_size]\n",
    "            src_mask: Tensor, shape [seq_len, seq_len]\n",
    "\n",
    "        Returns:\n",
    "            output Tensor of shape [seq_len, batch_size, ntoken]\n",
    "        \"\"\"\n",
    "#         src = self.encoder(src) * math.sqrt(self.embedding_dim)\n",
    "        src = self.pos_encoder(src * math.sqrt(self.input_embedding_dim))\n",
    "        output = self.transformer_encoder(src, src_mask)\n",
    "        output = self.mlp_head(output)\n",
    "        \n",
    "        return output\n",
    "    \n",
    "    \n",
    "def generate_square_subsequent_mask(sz: int) -> Tensor:\n",
    "    \"\"\"Generates an upper-triangular matrix of -inf, with zeros on diag.\"\"\"\n",
    "    return torch.triu(torch.ones(sz, sz) * float('-inf'), diagonal=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "624a2384",
   "metadata": {},
   "source": [
    "##### test block"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "c4ce687b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initiate an instance\n",
    "# The model hyperparameters are defined below. The vocab size is equal to the length of the vocab object.\n",
    "test_input_embedding_dim = 768  # embedding dimension\n",
    "test_output_feature_dim = 1024  # output feature dimension\n",
    "test_nhead = 2  # number of heads in nn.MultiheadAttention\n",
    "test_feedforward_dim = 768  # dimension of the feedforward network model in nn.TransformerEncoder\n",
    "test_nlayers = 2  # number of nn.TransformerEncoderLayer in nn.TransformerEncoder\n",
    "test_dropout = 0.2  # dropout probability\n",
    "\n",
    "# test_ntokens = 386  # size of vocabulary\n",
    "\n",
    "test_model = TransformerModel(test_input_embedding_dim,\n",
    "                              test_output_feature_dim,\n",
    "                              test_nhead,\n",
    "                              test_feedforward_dim, \n",
    "                              test_nlayers,\n",
    "                              test_dropout)  # .to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74650764",
   "metadata": {},
   "source": [
    "##### Run the model - example code\n",
    "\n",
    "We use `CrossEntropyLoss` with the `SGD (stochastic gradient descent)` optimizer. The `learning rate` is initially set to 5.0 and follows a `StepLR schedule`. During training, we use `nn.utils.clip_grad_norm_` to prevent gradients from exploding."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "7031f63f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy\n",
    "import time\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "# config ...\n",
    "# global variable ...\n",
    "bptt = 35\n",
    "batch_size = 20\n",
    "eval_batch_size = 10\n",
    "\n",
    "# create dataloader\n",
    "# TODO\n",
    "\n",
    "# create the model\n",
    "test_model = TransformerModel(test_ntokens,\n",
    "                              test_embedding_dim,\n",
    "                              test_nhead,\n",
    "                              test_feedforward_dim, \n",
    "                              test_nlayers,\n",
    "                              test_dropout).to(device)\n",
    "\n",
    "# create criterion, optimizer, scheduler\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "lr = 5.0\n",
    "optimizer = torch.optim.SGD(test_model.parameters(), lr=lr)\n",
    "scheduler = torch.optim.lr_scheduler.StepLR(optimizer, 1.0, gamma=0.95)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80c94e44",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model: nn.Module) -> None:\n",
    "    \n",
    "    # turn in train mode\n",
    "    test_model.train()\n",
    "    \n",
    "    # variable initialization\n",
    "    total_loss = 0.\n",
    "    log_interval = 200\n",
    "    start_time = time.time()\n",
    "    src_mask = generate_square_subsequent_mask().to(device)\n",
    "    \n",
    "    num_batches = len(train_data) // bptt\n",
    "    for batch, i in enumerate(range(0, train_data.size(0) - 1, bptt)):\n",
    "#         data, targets = get_batch(train_data, i)\n",
    "#         batch_size = data.size(0)\n",
    "        if batch_size != bptt:  # only on last batch\n",
    "            src_mask = src_mask[:batch_size, :batch_size]\n",
    "        output = model(data, src_mask)\n",
    "        loss = criterion(output.view(-1, ntokens), targets)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), 0.5)\n",
    "        optimizer.step()\n",
    "\n",
    "        total_loss += loss.item()\n",
    "        if batch % log_interval == 0 and batch > 0:\n",
    "            lr = scheduler.get_last_lr()[0]\n",
    "            ms_per_batch = (time.time() - start_time) * 1000 / log_interval\n",
    "            cur_loss = total_loss / log_interval\n",
    "            ppl = math.exp(cur_loss)\n",
    "            print(f'| epoch {epoch:3d} | {batch:5d}/{num_batches:5d} batches | '\n",
    "                  f'lr {lr:02.2f} | ms/batch {ms_per_batch:5.2f} | '\n",
    "                  f'loss {cur_loss:5.2f} | ppl {ppl:8.2f}')\n",
    "            total_loss = 0\n",
    "            start_time = time.time()\n",
    "            \n",
    "def evaluate(model: nn.Module, eval_data: Tensor) -> float:\n",
    "    model.eval()  # turn on evaluation mode\n",
    "    total_loss = 0.\n",
    "    src_mask = generate_square_subsequent_mask(bptt).to(device)\n",
    "    with torch.no_grad():\n",
    "        for i in range(0, eval_data.size(0) - 1, bptt):\n",
    "            data, targets = get_batch(eval_data, i)\n",
    "            batch_size = data.size(0)\n",
    "            if batch_size != bptt:\n",
    "                src_mask = src_mask[:batch_size, :batch_size]\n",
    "            output = model(data, src_mask)\n",
    "            output_flat = output.view(-1, ntokens)\n",
    "            total_loss += batch_size * criterion(output_flat, targets).item()\n",
    "    return total_loss / (len(eval_data) - 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bb84234",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_val_loss = float('inf')\n",
    "epochs = 3\n",
    "best_model = None\n",
    "\n",
    "for epoch in range(1, epochs + 1):\n",
    "    epoch_start_time = time.time()\n",
    "    train(model)\n",
    "    val_loss = evaluate(model, val_data)\n",
    "    val_ppl = math.exp(val_loss)\n",
    "    elapsed = time.time() - epoch_start_time\n",
    "    print('-' * 89)\n",
    "    print(f'| end of epoch {epoch:3d} | time: {elapsed:5.2f}s | '\n",
    "          f'valid loss {val_loss:5.2f} | valid ppl {val_ppl:8.2f}')\n",
    "    print('-' * 89)\n",
    "\n",
    "    if val_loss < best_val_loss:\n",
    "        best_val_loss = val_loss\n",
    "        best_model = copy.deepcopy(model)\n",
    "\n",
    "    scheduler.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67b99393",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_loss = evaluate(best_model, test_data)\n",
    "test_ppl = math.exp(test_loss)\n",
    "print('=' * 89)\n",
    "print(f'| End of training | test loss {test_loss:5.2f} | '\n",
    "      f'test ppl {test_ppl:8.2f}')\n",
    "print('=' * 89)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03269d38",
   "metadata": {},
   "source": [
    "## - evaluator.py (MUSDL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad1e3096",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "\n",
    "# TODO !!!\n",
    "# from opts import *\n",
    "\n",
    "# TODO !!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a70ea750",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MLP_block(nn.Module):\n",
    "\n",
    "    def __init__(self, feature_dim, output_dim):\n",
    "        super(MLP_block, self).__init__()\n",
    "        self.activation = nn.ReLU()\n",
    "        self.softmax = nn.Softmax(dim=-1)\n",
    "        self.layer1 = nn.Linear(feature_dim, 256)\n",
    "        self.layer2 = nn.Linear(256, 128)\n",
    "        self.layer3 = nn.Linear(128, output_dim)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.activation(self.layer1(x))\n",
    "        x = self.activation(self.layer2(x))\n",
    "        output = self.softmax(self.layer3(x))\n",
    "        return output\n",
    "\n",
    "\n",
    "class Evaluator(nn.Module):\n",
    "\n",
    "    def __init__(self, feature_dim, output_dim, num_subscores=None):\n",
    "        super(Evaluator, self).__init__()\n",
    "\n",
    "        self.model_type = 'MUSDL'\n",
    "        \n",
    "        assert num_subscores is not None, 'num_subscores is required in MUSDL'\n",
    "        self.evaluator = nn.ModuleList([MLP_block(feature_dim, output_dim) for _ in range(num_subscores)])\n",
    "\n",
    "    def forward(self, feats_avg):  # data: NCTHW\n",
    "        probs = [evaluator(feats_avg) for evaluator in self.evaluator]  # len=num_subscores\n",
    "        return probs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6edd94f4",
   "metadata": {},
   "source": [
    "# Configs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63697cde",
   "metadata": {},
   "outputs": [],
   "source": [
    "# where to store the outputs either relative path or absolute\n",
    "OUTPUT_DIR: exp\n",
    "# where to store the all the checkpoints of the model\n",
    "CKPTS_DIR: ckpts\n",
    "# randon seed \n",
    "MANUAL_SEED: 1\n",
    "# A: audio, V: visual, L: linguistic(text), AVL: combination\n",
    "# choices=['A+MUSDL', 'V+MUSDL', 'L+MUSDL','AV+MUSDL', 'AL+MUSDL', 'AVL+MUSDL']\n",
    "TYPE: L+MUSDL\n",
    "LOG_TITLE: L+MUSDL\n",
    "\n",
    "DATA:\n",
    "  ROOT_DIR: None\n",
    "  BATCH_SIZE: 2\n",
    "  SHUFFLE: False\n",
    "  NUM_WORKERS: 2\n",
    "    \n",
    "MODEL:\n",
    "  PATH: model_weights # path to folder where stores the best model weights\n",
    "  WEIGHTS: new  # new, last or custom path\n",
    "  epochs:\n",
    "  TRANSFORMER:\n",
    "    INPUT_EMBEDDING_DIM: 768\n",
    "    OUTPUT_FEATURE_DIM: 1024\n",
    "    N_HEAD: 2\n",
    "    FEEDFORWARD_DIM: 768\n",
    "    N_LAYERS: 2\n",
    "    DROPOUT: 0.2\n",
    "  MUSDL:\n",
    "    N_CLASSES: 4  # [0, 1, 2, 3]\n",
    "    N_SUBSCORES: 8\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fcb297b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c6dd58c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_parser():\n",
    "    parser = argparse.ArgumentParser()\n",
    "    parser.add_argument('--config_file',\n",
    "                        type=str,\n",
    "                        help=\"path to yaml file\",\n",
    "                        required=True,\n",
    "                        default=None)\n",
    "    \n",
    "    parser.add_argument('--device',\n",
    "                        type=str,\n",
    "                        help=\"set up torch device: 'cpu' or 'cuda' (GPU)\",\n",
    "                        required=False,\n",
    "                        default=torch.device('cuda' if torch.cuda.is_available() else 'cpu'))\n",
    "    \n",
    "    # remember to set the gpu device number \n",
    "    parser.add_argument('--gpu',\n",
    "                        type=str,\n",
    "                        help='id of gpu device(s) to be used',\n",
    "                        default='2, 3')\n",
    "\n",
    "    return parser"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8c5ba59",
   "metadata": {},
   "source": [
    "# utils.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e8a01e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import random\n",
    "import logging\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import transforms\n",
    "\n",
    "# local functions\n",
    "from dataset import DepressionDataset, Padding, ToTensor\n",
    "from models.transformer import TransformerModel\n",
    "from models.evaluator import Evaluator\n",
    "\n",
    "\n",
    "# import numpy as np\n",
    "# import seaborn as sns\n",
    "# import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "1414abc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def init_seed(manual_seed):\n",
    "    \"\"\"\n",
    "    Set random seed for torch and numpy.\n",
    "    \"\"\"\n",
    "    random.seed(manual_seed)\n",
    "    np.random.seed(manual_seed)\n",
    "    torch.manual_seed(manual_seed)\n",
    "\n",
    "    torch.cuda.manual_seed_all(manual_seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "\n",
    "    \n",
    "def get_logger(filepath, log_title):\n",
    "    logger = logging.getLogger(filepath)\n",
    "    logger.setLevel(logging.INFO)\n",
    "    fh = logging.FileHandler(filepath)\n",
    "    fh.setLevel(logging.INFO)\n",
    "    logger.addHandler(fh)\n",
    "    logger.info('-' * 30 + log_title + '-' * 30)\n",
    "    return logger\n",
    "\n",
    "\n",
    "def log_and_print(logger, msg):\n",
    "    logger.info(msg)\n",
    "    print(msg)\n",
    "\n",
    "\n",
    "def worker_init_fn(worker_id):\n",
    "    \"\"\"\n",
    "    Init worker in dataloader.\n",
    "    \"\"\"\n",
    "    np.random.seed(np.random.get_state()[1][0] + worker_id)\n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "def get_dataloaders(config):\n",
    "    \n",
    "    train_dataset = DepressionDataset(config['ROOT_DIR'], 'train',\n",
    "                                      transform=transforms.Compose([Padding(), ToTensor()]))\n",
    "    validation_dataset = DepressionDataset(config['ROOT_DIR'], 'dev',\n",
    "                                           transform=transforms.Compose([Padding(), ToTensor()]))\n",
    "    \n",
    "    dataloaders = {}\n",
    "    \n",
    "    dataloaders['train'] = DataLoader(DepressionDataset,\n",
    "                                      batch_size=config['BATCH_SIZE'],\n",
    "                                      shuffle=config['SHUFFLE'], \n",
    "                                      num_workers=config['NUM_WORKERS'])\n",
    "    \n",
    "    dataloaders['validation'] = DataLoader(DepressionDataset, \n",
    "                                           batch_size=config['BATCH_SIZE'],\n",
    "                                           shuffle=config['SHUFFLE'],\n",
    "                                           num_workers=config['NUM_WORKERS'])\n",
    "    \n",
    "    return dataloaders\n",
    "\n",
    "\n",
    "def get_models(config, args):\n",
    "    \"\"\"\n",
    "    Get the Transformer encoder backbone and the evaluator(MUSDL) with parameters moved to GPU.\n",
    "    \"\"\"\n",
    "    \n",
    "    transformer = TransformerModel(config['TRANSFORMER']['INPUT_EMBEDDING_DIM'], \n",
    "                                   config['TRANSFORMER']['OUTPUT_FEATURE_DIM'],\n",
    "                                   config['TRANSFORMER']['N_HEAD'],\n",
    "                                   config['TRANSFORMER']['FEEDFORWARD_DIM'],\n",
    "                                   config['TRANSFORMER']['N_LAYERS'],\n",
    "                                   config['TRANSFORMER']['DROPOUT'])\n",
    "        \n",
    "    evaluator = Evaluator(config['TRANSFORMER']['OUTPUT_FEATURE_DIM'],\n",
    "                          config['MUSDL']['N_CLASSES'], \n",
    "                          config['MUSDL']['N_SUBSCORES'])\n",
    "\n",
    "    if len(args.gpu.split(',')) > 1:\n",
    "        transformer = nn.DataParallel(transformer)\n",
    "        evaluator = nn.DataParallel(evaluator)\n",
    "    \n",
    "    # move to GPU\n",
    "    transformer = transformer.to(args.device)\n",
    "    evaluator = evaluator.to(args.device)\n",
    "    \n",
    "    return transformer, evaluator\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09806f23",
   "metadata": {},
   "source": [
    "# Main"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a67a7bd1",
   "metadata": {},
   "source": [
    "Overall architecture of system folders and scripts\n",
    "\n",
    "```\n",
    "[Text+MUSDL]\n",
    " ├── [models]\n",
    " │    ├── transformer.py (Transformer model)\n",
    " │    └── evaluator.py (MUSDL model)\n",
    " ├── [dataset]\n",
    " │    ├── dataset.py\n",
    " │    └── utils.py\n",
    " ├── [cfg]\n",
    " │    ├── train_config.yaml\n",
    " │    ├── test_config.yaml\n",
    " │    └── inference_config.yaml\n",
    " ├── utils.py\n",
    " ├── train.py\n",
    " ├── test.py\n",
    " ├── inference.py\n",
    " │\n",
    " ├── [model_weights]\n",
    " │    └── store only one of the best model overall\n",
    " ├── [exp]\n",
    " │    └── 存所有實驗結果, train, test, inference\n",
    " ├── [ckpts]\n",
    " │    └── 暫存所有model weights\n",
    " └── ...\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08315c23",
   "metadata": {},
   "source": [
    "# main: Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a6ac6f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO\n",
    "\n",
    "import os\n",
    "import sys\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import transforms\n",
    "\n",
    "from scipy import stats\n",
    "from tqdm import tqdm\n",
    "from autolab_core import YamlConfig\n",
    "\n",
    "# local functions\n",
    "from dataset import DepressionDataset, Padding, ToTensor\n",
    "from models.transformer import TransformerModel\n",
    "from models.evaluator import Evaluator\n",
    "\n",
    "######################################################\n",
    "from utils import *\n",
    "# from opts import *\n",
    "# from config import get_parser\n",
    "\n",
    "# TODO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0c58180",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def compute_score(model_type, probs, data):\n",
    "    if model_type == 'USDL':\n",
    "        pred = probs.argmax(dim=-1) * (label_max / (output_dim['USDL']-1))\n",
    "    else:\n",
    "        # calculate expectation & denormalize & sort\n",
    "        judge_scores_pred = torch.stack([prob.argmax(dim=-1) * judge_max / (output_dim['MUSDL']-1)\n",
    "                                         for prob in probs], dim=1).sort()[0]  # N, 7\n",
    "\n",
    "        # keep the median 3 scores to get final score according to the rule of diving\n",
    "        pred = torch.sum(judge_scores_pred[:, 2:5], dim=1) * data['difficulty'].cuda()\n",
    "    return pred\n",
    "\n",
    "\n",
    "def compute_loss(model_type, criterion, probs, data):\n",
    "    if model_type == 'USDL':\n",
    "        loss = criterion(torch.log(probs), data['soft_label'].cuda())\n",
    "    else:\n",
    "        loss = sum([criterion(torch.log(probs[i]), data['soft_judge_scores'][:, i].cuda()) for i in range(num_judges)])\n",
    "    return loss\n",
    "\n",
    "\n",
    "def main(dataloaders, i3d, evaluator, base_logger, args):\n",
    "    # print configuration\n",
    "    '''\n",
    "    use: print(config.file_contents)\n",
    "    also: store the config.save(os.path.join(path, name))\n",
    "        path: config['OUTPUT_DIR']\n",
    "        name: config['SAVE_CONFIG_NAME']\n",
    "    '''\n",
    "    print('=' * 40)\n",
    "    for k, v in vars(args).items():\n",
    "        print(f'{k}: {v}')\n",
    "    print('=' * 40)\n",
    "\n",
    "    criterion = nn.KLDivLoss()\n",
    "    optimizer = torch.optim.Adam([*i3d.parameters()] + [*evaluator.parameters()],\n",
    "                                 lr=args.lr, weight_decay=args.weight_decay)\n",
    "\n",
    "    epoch_best = 0\n",
    "    rho_best = 0\n",
    "    for epoch in range(args.num_epochs):\n",
    "        log_and_print(base_logger, f'Epoch: {epoch}  Current Best: {rho_best} at epoch {epoch_best}')\n",
    "\n",
    "        for split in ['train', 'test']:\n",
    "            true_scores = []\n",
    "            pred_scores = []\n",
    "\n",
    "            if split == 'train':\n",
    "                i3d.train()\n",
    "                evaluator.train()\n",
    "                torch.set_grad_enabled(True)\n",
    "            else:\n",
    "                i3d.eval()\n",
    "                evaluator.eval()\n",
    "                torch.set_grad_enabled(False)\n",
    "\n",
    "            for data in tqdm(dataloaders[split]):\n",
    "                true_scores.extend(data['final_score'].numpy())\n",
    "                videos = data['video'].cuda()\n",
    "                videos.transpose_(1, 2)  # N, C, T, H, W\n",
    "\n",
    "                batch_size, C, frames, H, W = videos.shape\n",
    "                clip_feats = torch.empty(batch_size, 10, feature_dim).cuda()\n",
    "                for i in range(9):\n",
    "                    clip_feats[:, i] = i3d(videos[:, :, 10 * i:10 * i + 16, :, :]).squeeze(2)\n",
    "                clip_feats[:, 9] = i3d(videos[:, :, -16:, :, :]).squeeze(2)\n",
    "\n",
    "                probs = evaluator(clip_feats.mean(1))\n",
    "                preds = compute_score(args.type, probs, data)\n",
    "                pred_scores.extend([i.item() for i in preds])\n",
    "\n",
    "                if split == 'train':\n",
    "                    loss = compute_loss(args.type, criterion, probs, data)\n",
    "                    optimizer.zero_grad()\n",
    "                    loss.backward()\n",
    "                    optimizer.step()\n",
    "\n",
    "            rho, p = stats.spearmanr(pred_scores, true_scores)\n",
    "\n",
    "            log_and_print(base_logger, f'{split} correlation: {rho}')\n",
    "\n",
    "        if rho > rho_best:\n",
    "            rho_best = rho\n",
    "            epoch_best = epoch\n",
    "            log_and_print(base_logger, '-----New best found!-----')\n",
    "            if args.save:\n",
    "                torch.save({'epoch': epoch,\n",
    "                            'i3d': i3d.state_dict(),\n",
    "                            'evaluator': evaluator.state_dict(),\n",
    "                            'optimizer': optimizer.state_dict(),\n",
    "                            'rho_best': rho_best}, f'ckpts/{args.type}.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52a417f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == '__main__':\n",
    "    \n",
    "    args = get_parser().parse_args()\n",
    "    \n",
    "    # set up GPU\n",
    "    if args.device == 'cuda':\n",
    "        os.environ['CUDA_VISIBLE_DEVICES'] = args.gpu\n",
    "    \n",
    "    # load config file into dict() format\n",
    "    config = YamlConfig(args.config_file)    \n",
    "    \n",
    "    # create output folder if not exist\n",
    "    if not os.path.exists(config['OUTPUT_DIR']):\n",
    "        os.mkdir(config['OUTPUT_DIR'])\n",
    "    if not os.path.exists(config['CKPTS_DIR']):\n",
    "        os.mkdir(config['CKPTS_DIR'])\n",
    "    if not os.path.exists(config['MODEL']['PATH']):\n",
    "        os.mkdir(config['MODEL']['PATH'])\n",
    "    \n",
    "    # initialize random seed for torch and numpy\n",
    "    init_seed(config['MANUAL_SEED'])\n",
    "    \n",
    "    # get logger os.path.join(config['OUTPUT_DIR'], f'{config['TYPE']}_{config['LOG_TITLE']}.log')\n",
    "    file_name = os.path.join(config['OUTPUT_DIR'], '{}_{}.log'.format(config['TYPE'], config['LOG_TITLE']))\n",
    "    base_logger = get_logger(file_name, config['LOG_TITLE'])\n",
    "    # get dataloaders\n",
    "    dataloaders = get_dataloaders(config['DATA'])\n",
    "    # get models\n",
    "    transformer, evaluator = get_models(config['MODEL'], args)\n",
    "    \n",
    "\n",
    "    main(dataloaders, i3d, evaluator, base_logger, args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bee2c4c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "c40ed03c",
   "metadata": {},
   "source": [
    "# Decide how to store the checkpoints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "49db14f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "\n",
    "# 先決定如何存ckpts\n",
    "if args.save:\n",
    "    # get the time for the file name\n",
    "    timestamp = datetime.utcnow().strftime('%Y-%m-%d_%H%M%S')  # exact: strftime('%Y-%m-%d %H%M%S%f')[:-3]\n",
    "    \n",
    "    # save\n",
    "    file_path = os.path.join(config['CKPTS_DIR'], \n",
    "                             '{}_{}.pt'.format(config['TYPE'], timestamp))\n",
    "    torch.save({'epoch': epoch,\n",
    "                'i3d': i3d.state_dict(),\n",
    "                'evaluator': evaluator.state_dict(),\n",
    "                'optimizer': optimizer.state_dict(),\n",
    "                'rho_best': rho_best}, file_path)\n",
    "\n",
    "'''EXP\n",
    "[ckpts (CKPTS_DIR)]\n",
    " └── [L+MUSDL (TYPE)]\n",
    "      ├── L+MUSDL_2021-12-28_114455\n",
    "      ├── L+MUSDL_2021-12-28_114458\n",
    "      ├── L+MUSDL_2021-12-28_114501\n",
    "      ├── L+MUSDL_2021-12-28_114504\n",
    "      └── ...\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f1c5c334",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2022-01-04_152837'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "datetime.utcnow().strftime('%Y-%m-%d_%H%M%S')  # strftime('%Y-%m-%d %H%M%S%f')[:-3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "492d3000",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-01-04 15:29:04.898\n",
      "1641310144.906261\n",
      "2022-01-04_162904\n"
     ]
    }
   ],
   "source": [
    "# another way to get time\n",
    "\n",
    "from datetime import datetime\n",
    "print(datetime.utcnow().strftime('%Y-%m-%d %H:%M:%S.%f')[:-3])\n",
    "# >>>> OUTPUT >>>>\n",
    "# 2020-05-04 10:18:32.926\n",
    "\n",
    "\n",
    "import time \n",
    "print(time.time())\n",
    "\n",
    "t = time.localtime()\n",
    "timestamp = time.strftime('%Y-%m-%d_%H%M%S', t)\n",
    "print(timestamp)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5da5300f",
   "metadata": {},
   "source": [
    "## function for find the last checkpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "109aca92",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_last_ckpts(path, key, date=None):\n",
    "    \"\"\"Finds the last checkpoint file of the last trained model in the\n",
    "    model directory.\n",
    "    Arguments:\n",
    "        path: str, path to the checkpoint\n",
    "        key: str, model type\n",
    "        date: str, a specific date in string format 'YYYY-MM-DD'\n",
    "    Returns:\n",
    "        The path of the last checkpoint file\n",
    "    \"\"\"\n",
    "    ckpts = list(sorted(os.listdir(path)))\n",
    "    \n",
    "    if date is not None:\n",
    "        # match the date format\n",
    "        date_format = \"%Y-%m-%d\"\n",
    "        try:\n",
    "            datetime.strptime(date, date_format)\n",
    "            # print(\"This is the correct date string format.\")\n",
    "            matched = True\n",
    "        except ValueError:\n",
    "            # print(\"This is the incorrect date string format. It should be YYYY-MM-DD\")\n",
    "            matched = False\n",
    "            \n",
    "        assert matched, \"The given date is the incorrect date string format. It should be YYYY-MM-DD\"\n",
    "        key = '{}_{}'.format(key, date)\n",
    "    else:\n",
    "        key = str(key)\n",
    "    \n",
    "    # filter the files\n",
    "    ckpts = list(filter(lambda f:f.startswith(key), ckpts))\n",
    "    # get whole file path\n",
    "    last_ckpt = os.path.join(path, ckpts[-1])\n",
    "    \n",
    "    return last_ckpt\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16d031cd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "a32187fc",
   "metadata": {},
   "source": [
    "## visualize the function of generate_square_subsequent_mask "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "00d870c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "def generate_square_subsequent_mask(sz: int):\n",
    "    \"\"\"Generates an upper-triangular matrix of -inf, with zeros on diag.\"\"\"\n",
    "    return torch.triu(torch.ones(sz, sz) * float('-inf'), diagonal=1)\n",
    "\n",
    "result = generate_square_subsequent_mask(35)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "04d33c96",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0., -inf, -inf,  ..., -inf, -inf, -inf],\n",
       "        [0., 0., -inf,  ..., -inf, -inf, -inf],\n",
       "        [0., 0., 0.,  ..., -inf, -inf, -inf],\n",
       "        ...,\n",
       "        [0., 0., 0.,  ..., 0., -inf, -inf],\n",
       "        [0., 0., 0.,  ..., 0., 0., -inf],\n",
       "        [0., 0., 0.,  ..., 0., 0., 0.]])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f89958b9",
   "metadata": {},
   "source": [
    "# other useful function for utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3881882d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def standard_confusion_matrix(y_test, y_test_pred):\n",
    "    \"\"\"\n",
    "    Make confusion matrix with format:\n",
    "                  -----------\n",
    "                  | TP | FP |\n",
    "                  -----------\n",
    "                  | FN | TN |\n",
    "                  -----------\n",
    "    Parameters\n",
    "    ----------\n",
    "    y_true : ndarray - 1D\n",
    "    y_pred : ndarray - 1D\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    ndarray - 2D\n",
    "    \"\"\"\n",
    "    [[tn, fp], [fn, tp]] = confusion_matrix(y_test, y_test_pred)\n",
    "    return np.array([[tp, fp], [fn, tn]])\n",
    "\n",
    "def model_performance(y_test, y_test_pred_proba):\n",
    "    \"\"\"\n",
    "    Evaluation metrics for network performance.\n",
    "    \"\"\"\n",
    "#     y_test_pred = y_test_pred_proba.data.max(1, keepdim=True)[1]\n",
    "    y_test_pred = y_test_pred_proba\n",
    "\n",
    "    # Computing confusion matrix for test dataset\n",
    "    conf_matrix = standard_confusion_matrix(y_test, y_test_pred)\n",
    "    print(\"Confusion Matrix:\")\n",
    "    print(conf_matrix)\n",
    "\n",
    "    return y_test_pred, conf_matrix\n",
    "\n",
    "def plot_roc_curve(y_test, y_score):\n",
    "    \"\"\"\n",
    "    Plots ROC curve for final trained model. Code taken from:\n",
    "    https://vkolachalama.blogspot.com/2016/05/keras-implementation-of-mlp-neural.html\n",
    "    \"\"\"\n",
    "    fpr, tpr, _ = roc_curve(y_test, y_score)\n",
    "    roc_auc = auc(fpr, tpr)\n",
    "    plt.figure()\n",
    "    plt.plot(fpr, tpr, label='ROC curve (area = %0.2f)' % roc_auc)\n",
    "    plt.plot([0, 1], [0, 1], 'k--')\n",
    "    plt.xlim([0.0, 1.05])\n",
    "    plt.ylim([0.0, 1.05])\n",
    "    plt.xlabel('False Positive Rate')\n",
    "    plt.ylabel('True Positive Rate')\n",
    "    plt.title('Receiver operating characteristic curve')\n",
    "    plt.legend(loc=\"lower right\")\n",
    "    plt.savefig(prefix+'images/BiLSTM_roc.png')\n",
    "    plt.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
