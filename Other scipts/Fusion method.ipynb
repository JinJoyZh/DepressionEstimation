{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "52e682a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "# sum, mean, median, multiplication, concat, majority voting"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b1f7821",
   "metadata": {},
   "source": [
    "# Sum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "b192cf1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "input1 = torch.randn(2, 128)\n",
    "input2 = torch.randn(2, 128)\n",
    "input3 = torch.randn(2, 128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "b1c6bcbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "output = input1 + input2 + input3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "6c85d762",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 128])"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "6dd8e6a0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([ 0.4083, -0.4796, -0.8383,  1.3664,  0.8150, -1.1856,  0.0075, -0.2266]),\n",
       " tensor([0.3041, 0.4121, 1.1434, 1.2350, 0.7089, 0.7158, 0.9989, 1.0971]),\n",
       " tensor([-0.3913,  0.6618,  0.3074, -0.3041, -1.5659, -3.1922,  1.5595,  0.8624]),\n",
       " tensor([ 0.3211,  0.5943,  0.6125,  2.2972, -0.0420, -3.6620,  2.5659,  1.7329]))"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input1[0, :8], input2[0, :8], input3[0, :8], output[0, :8]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59189d3a",
   "metadata": {},
   "source": [
    "# Mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "fe274f87",
   "metadata": {},
   "outputs": [],
   "source": [
    "input1 = torch.randn(2, 128)\n",
    "input2 = torch.randn(2, 128)\n",
    "input3 = torch.randn(2, 128)\n",
    "\n",
    "output = (input1 + input2 + input3) / 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "aa1ee1ba",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([ 0.4083, -0.4796, -0.8383,  1.3664,  0.8150, -1.1856,  0.0075, -0.2266]),\n",
       " tensor([0.3041, 0.4121, 1.1434, 1.2350, 0.7089, 0.7158, 0.9989, 1.0971]),\n",
       " tensor([-0.3913,  0.6618,  0.3074, -0.3041, -1.5659, -3.1922,  1.5595,  0.8624]),\n",
       " tensor([ 0.3211,  0.5943,  0.6125,  2.2972, -0.0420, -3.6620,  2.5659,  1.7329]))"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input1[0, :8], input2[0, :8], input3[0, :8], output[0, :8]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72ecf6c4",
   "metadata": {},
   "source": [
    "# Median"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "4c26c15c",
   "metadata": {},
   "outputs": [],
   "source": [
    "input1 = torch.randn(2, 128)\n",
    "input2 = torch.randn(2, 128)\n",
    "input3 = torch.randn(2, 128)\n",
    "\n",
    "output = torch.median(torch.stack([input1, input2, input3], axis=-1), dim=-1).values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "72756dfa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([-0.0925,  0.6890,  0.8991, -0.4572, -0.1507,  0.3859,  1.0516,  1.1450]),\n",
       " tensor([-0.0080, -1.3823,  1.6848, -0.5771,  0.4616, -0.6396,  1.2812,  0.4066]),\n",
       " tensor([ 0.5534,  1.0167, -0.8309,  0.5735, -0.2075, -1.1470,  0.9102, -0.2691]),\n",
       " tensor([-0.0080,  0.6890,  0.8991, -0.4572, -0.1507, -0.6396,  1.0516,  0.4066]))"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input1[0, :8], input2[0, :8], input3[0, :8], output[0, :8]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53eef462",
   "metadata": {},
   "source": [
    "# Multiplication"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "bf8b91ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "input1 = torch.randn(2, 128)\n",
    "input2 = torch.randn(2, 128)\n",
    "input3 = torch.randn(2, 128)\n",
    "\n",
    "output = input1 * input2 * input3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "84a049e0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([ 2.4554, -0.9643,  0.9821,  0.1239, -0.5007,  0.4908, -3.3054, -0.8331]),\n",
       " tensor([-0.0352,  0.2774,  0.7817,  0.3312,  1.2934, -0.1818,  0.9694, -0.1265]),\n",
       " tensor([-1.3112,  0.3359,  0.4569,  1.6736, -0.2904,  1.0600,  1.1344,  1.7350]),\n",
       " tensor([ 0.1134, -0.0899,  0.3508,  0.0687,  0.1880, -0.0946, -3.6349,  0.1828]))"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input1[0, :8], input2[0, :8], input3[0, :8], output[0, :8]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56dbd64d",
   "metadata": {},
   "source": [
    "# Maximum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ffbf86f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "input1 = torch.randn(2, 128)\n",
    "input2 = torch.randn(2, 128)\n",
    "input3 = torch.randn(2, 128)\n",
    "\n",
    "output = torch.stack([input1, input2, input3], axis=-1).max(dim=-1).values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "6b8787db",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([ 0.6940, -0.3635, -2.1909, -0.6600,  0.3839, -0.9171,  0.7914, -0.3492]),\n",
       " tensor([-1.1887, -1.0842,  0.4854, -0.2497, -0.1989, -2.0303, -1.7055, -0.6507]),\n",
       " tensor([ 0.4384, -0.1163, -0.4438,  0.0712, -1.3231,  0.9429,  0.9035,  0.4979]),\n",
       " tensor([ 0.6940, -0.1163,  0.4854,  0.0712,  0.3839,  0.9429,  0.9035,  0.4979]))"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input1[0, :8], input2[0, :8], input3[0, :8], output[0, :8]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d3018eda",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 128])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70c110f3",
   "metadata": {},
   "source": [
    "# Concatenate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "360feaee",
   "metadata": {},
   "outputs": [],
   "source": [
    "input1 = torch.randn(2, 128)\n",
    "input2 = torch.randn(2, 128)\n",
    "input3 = torch.randn(2, 128)\n",
    "\n",
    "output = torch.cat([input1, input2, input3], dim=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "07fb5515",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 384])"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "443ef598",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "45d9daa8",
   "metadata": {},
   "source": [
    "# Attention Bottlenecks for Multimodal Fusion\n",
    "\n",
    "form paper Attentional Feature Fusion from Dai et al.\n",
    "\n",
    "Credential: code origiate from https://github.com/YimianDai/open-aff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "84928ef7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 5, 128])\n",
      "torch.Size([2, 1, 5, 128])\n"
     ]
    }
   ],
   "source": [
    "exp_input = torch.stack([input1, input2, input1, input2, input1], dim=1)\n",
    "B, H, W = exp_input.shape\n",
    "print(exp_input.shape)\n",
    "\n",
    "exp_input = exp_input.unsqueeze(dim=1)  # same as exp_input.view(B, 1, H, W)\n",
    "print(exp_input.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "6500e27b",
   "metadata": {},
   "outputs": [],
   "source": [
    "conv2X2 = nn.Conv2d(64, 16, kernel_size=3, stride=1,\n",
    "                    padding=1, groups=1, bias=False, dilation=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "db8d933d",
   "metadata": {},
   "outputs": [],
   "source": [
    "a = torch.randn([2, 64, 5, 128])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "a171da4e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 16, 5, 128])"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result = conv2X2(a)\n",
    "result.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c27e23db",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "2c10badf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "\n",
    "class DAF(nn.Module):\n",
    "    '''\n",
    "    直接相加 DirectAddFuse\n",
    "    '''\n",
    "\n",
    "    def __init__(self):\n",
    "        super(DAF, self).__init__()\n",
    "\n",
    "    def forward(self, x, residual):\n",
    "        return x + residual\n",
    "\n",
    "\n",
    "class iAFF(nn.Module):\n",
    "    '''\n",
    "    多特征融合 iAFF\n",
    "    '''\n",
    "\n",
    "    def __init__(self, channels=64, r=4):\n",
    "        super(iAFF, self).__init__()\n",
    "        inter_channels = int(channels // r)\n",
    "\n",
    "        # 本地注意力\n",
    "        self.local_att = nn.Sequential(\n",
    "            nn.Conv2d(channels, inter_channels, kernel_size=1, stride=1, padding=0),\n",
    "            nn.BatchNorm2d(inter_channels),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(inter_channels, channels, kernel_size=1, stride=1, padding=0),\n",
    "            nn.BatchNorm2d(channels),\n",
    "        )\n",
    "\n",
    "        # 全局注意力\n",
    "        self.global_att = nn.Sequential(\n",
    "            nn.AdaptiveAvgPool2d(1),\n",
    "            nn.Conv2d(channels, inter_channels, kernel_size=1, stride=1, padding=0),\n",
    "            nn.BatchNorm2d(inter_channels),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(inter_channels, channels, kernel_size=1, stride=1, padding=0),\n",
    "            nn.BatchNorm2d(channels),\n",
    "        )\n",
    "\n",
    "        # 第二次本地注意力\n",
    "        self.local_att2 = nn.Sequential(\n",
    "            nn.Conv2d(channels, inter_channels, kernel_size=1, stride=1, padding=0),\n",
    "            nn.BatchNorm2d(inter_channels),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(inter_channels, channels, kernel_size=1, stride=1, padding=0),\n",
    "            nn.BatchNorm2d(channels),\n",
    "        )\n",
    "        # 第二次全局注意力\n",
    "        self.global_att2 = nn.Sequential(\n",
    "            nn.AdaptiveAvgPool2d(1),\n",
    "            nn.Conv2d(channels, inter_channels, kernel_size=1, stride=1, padding=0),\n",
    "            nn.BatchNorm2d(inter_channels),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(inter_channels, channels, kernel_size=1, stride=1, padding=0),\n",
    "            nn.BatchNorm2d(channels),\n",
    "        )\n",
    "\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "\n",
    "    def forward(self, x, residual):\n",
    "        xa = x + residual\n",
    "        xl = self.local_att(xa)\n",
    "        xg = self.global_att(xa)\n",
    "        xlg = xl + xg\n",
    "        wei = self.sigmoid(xlg)\n",
    "        xi = x * wei + residual * (1 - wei)\n",
    "\n",
    "        xl2 = self.local_att2(xi)\n",
    "        xg2 = self.global_att(xi)\n",
    "        xlg2 = xl2 + xg2\n",
    "        wei2 = self.sigmoid(xlg2)\n",
    "        xo = x * wei2 + residual * (1 - wei2)\n",
    "        return xo\n",
    "\n",
    "\n",
    "class AFF(nn.Module):\n",
    "    '''\n",
    "    多特征融合 AFF\n",
    "    '''\n",
    "\n",
    "    def __init__(self, channels=64, r=4):\n",
    "        super(AFF, self).__init__()\n",
    "        inter_channels = int(channels // r)\n",
    "\n",
    "        self.local_att = nn.Sequential(\n",
    "            nn.Conv2d(channels, inter_channels, kernel_size=1, stride=1, padding=0),\n",
    "            nn.BatchNorm2d(inter_channels),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(inter_channels, channels, kernel_size=1, stride=1, padding=0),\n",
    "            nn.BatchNorm2d(channels),\n",
    "        )\n",
    "\n",
    "        self.global_att = nn.Sequential(\n",
    "            nn.AdaptiveAvgPool2d(1),\n",
    "            nn.Conv2d(channels, inter_channels, kernel_size=1, stride=1, padding=0),\n",
    "            nn.BatchNorm2d(inter_channels),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(inter_channels, channels, kernel_size=1, stride=1, padding=0),\n",
    "            nn.BatchNorm2d(channels),\n",
    "        )\n",
    "\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "\n",
    "    def forward(self, x, residual):\n",
    "        xa = x + residual\n",
    "        xl = self.local_att(xa)\n",
    "        xg = self.global_att(xa)\n",
    "        xlg = xl + xg\n",
    "        wei = self.sigmoid(xlg)\n",
    "\n",
    "        xo = 2 * x * wei + 2 * residual * (1 - wei)\n",
    "        return xo\n",
    "    \n",
    "    \n",
    "def conv1x1(in_channels, out_channels, stride=1):\n",
    "    \"\"\"1x1 convolution\"\"\"\n",
    "    return nn.Conv2d(in_channels, out_channels, kernel_size=1, stride=stride, bias=False)\n",
    "\n",
    "\n",
    "def conv3x3(in_channels, out_channels, stride=1, groups=1, dilation=1):\n",
    "    \"\"\"3x3 convolution with padding\"\"\"\n",
    "    return nn.Conv2d(in_channels, out_channels, kernel_size=3, stride=stride,\n",
    "                     padding=dilation, groups=groups, bias=False, dilation=dilation)\n",
    "\n",
    "def conv5x5(in_channels, out_channels, stride=1, groups=1, dilation=1):\n",
    "    \"\"\"5x5 convolution with padding\"\"\"\n",
    "    return nn.Conv2d(in_channels, out_channels, kernel_size=5, stride=stride,\n",
    "                     padding=2, groups=groups, bias=False, dilation=dilation)\n",
    "\n",
    "\n",
    "class Bottleneck(nn.Module):\n",
    "    # Bottleneck in torchvision places the stride for downsampling at 3x3 convolution(self.conv2)\n",
    "    # while original implementation places the stride at the first 1x1 convolution(self.conv1)\n",
    "    # according to \"Deep residual learning for image recognition\"https://arxiv.org/abs/1512.03385.\n",
    "    # This variant is also known as ResNet V1.5 and improves accuracy according to\n",
    "    # https://ngc.nvidia.com/catalog/model-scripts/nvidia:resnet_50_v1_5_for_pytorch.\n",
    "    \n",
    "    expansion = 16\n",
    "\n",
    "    def __init__(self, inplanes, planes, base_width=64,\n",
    "                 fuse_type='DAF', stride=1, groups=1, dilation=1):\n",
    "        super(Bottleneck, self).__init__()\n",
    "        \n",
    "        norm_layer = nn.BatchNorm2d\n",
    "        width = int(planes * (base_width / 64.)) * groups\n",
    "        # Both self.conv2 and self.downsample layers downsample the input when stride != 1\n",
    "        self.conv1 = conv1x1(inplanes, width)\n",
    "        self.bn1 = norm_layer(width)\n",
    "        self.conv2 = conv5x5(width, width, stride, groups, dilation)\n",
    "        self.bn2 = norm_layer(width)\n",
    "        self.conv3 = conv1x1(width, planes * self.expansion)\n",
    "        self.bn3 = norm_layer(planes * self.expansion)\n",
    "        self.conv4 = conv5x5(planes * self.expansion, width, stride, groups, dilation)\n",
    "        self.bn4 = norm_layer(width)\n",
    "        self.conv5 = conv1x1(width, inplanes)\n",
    "        self.bn5 = norm_layer(inplanes)        \n",
    "        \n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        self.stride = stride\n",
    "\n",
    "        if fuse_type == 'AFF':\n",
    "            self.fuse_mode = AFF(channels=planes * self.expansion)\n",
    "        elif fuse_type == 'iAFF':\n",
    "            self.fuse_mode = iAFF(channels=planes * self.expansion)\n",
    "        elif fuse_type == 'DAF':\n",
    "            self.fuse_mode = DAF()\n",
    "        else:\n",
    "            self.fuse_mode = None\n",
    "            \n",
    "        for m in self.modules():\n",
    "            if isinstance(m, nn.Conv2d):\n",
    "                nn.init.kaiming_normal_(m.weight, mode='fan_out', nonlinearity='relu')\n",
    "            elif isinstance(m, (nn.BatchNorm2d, nn.GroupNorm)):\n",
    "                nn.init.constant_(m.weight, 1)\n",
    "                nn.init.constant_(m.bias, 0)\n",
    "\n",
    "    def forward(self, x):\n",
    "        identity = x\n",
    "\n",
    "        out = self.conv1(x)\n",
    "        out = self.bn1(out)\n",
    "        out = self.relu(out)\n",
    "\n",
    "        out = self.conv2(out)\n",
    "        out = self.bn2(out)\n",
    "        out = self.relu(out)\n",
    "\n",
    "        out = self.conv3(out)\n",
    "        out = self.bn3(out)\n",
    "\n",
    "        # out += identity\n",
    "        out = self.fuse_mode(out, identity)\n",
    "        out = self.relu(out)\n",
    "        \n",
    "        out = self.conv4(out)\n",
    "        out = self.bn4(out)\n",
    "        out = self.relu(out)\n",
    "\n",
    "        out = self.conv5(out)\n",
    "        out = self.bn5(out)\n",
    "        out = self.relu(out)\n",
    "        \n",
    "        return out\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "e5592334",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 5, 128])\n",
      "torch.Size([2, 1, 5, 128])\n"
     ]
    }
   ],
   "source": [
    "input1 = torch.randn(2, 128)\n",
    "input2 = torch.randn(2, 128)\n",
    "input3 = torch.randn(2, 128)\n",
    "\n",
    "exp_input = torch.stack([input1, input2, input1, input3, input2], dim=1)\n",
    "B, H, W = exp_input.shape\n",
    "print(exp_input.shape)\n",
    "\n",
    "exp_input = exp_input.unsqueeze(dim=1)  # same as exp_input.view(B, 1, H, W)\n",
    "print(exp_input.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "347c312d",
   "metadata": {},
   "outputs": [],
   "source": [
    "fusion_layer = Bottleneck(inplanes=1, planes=4, base_width=256, fuse_type='iAFF')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "b3b3acb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "result = fusion_layer(exp_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "246947f0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 1, 5, 128])"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "532946ed",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 640])"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "B, C, H, W = result.shape\n",
    "result = result.view(B, -1)\n",
    "\n",
    "result.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca27bd1c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "a87c4082",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 4, 128])\n",
      "torch.Size([2, 1, 4, 128])\n"
     ]
    }
   ],
   "source": [
    "input1 = torch.randn(2, 128)\n",
    "input2 = torch.randn(2, 128)\n",
    "input3 = torch.randn(2, 128)\n",
    "\n",
    "exp_input = torch.stack([input1, input2, input1, input3], dim=1)\n",
    "B, H, W = exp_input.shape\n",
    "print(exp_input.shape)\n",
    "\n",
    "exp_input = exp_input.unsqueeze(dim=1)  # same as exp_input.view(B, 1, H, W)\n",
    "print(exp_input.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "a4388dfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "fusion_layer = Bottleneck(inplanes=1, planes=4, base_width=256, fuse_type='iAFF')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "91d21dd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "result = fusion_layer(exp_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "64006746",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 1, 4, 128])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "611f35a4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a56434ee",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7816dff4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2587422c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85c74ed5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2e60767",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6bacc9c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a900c887",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "487db32e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95e5b5fc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c9397e8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df01b263",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98481030",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cddfe56a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "845a29c0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5e20a36",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "205c9a7e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a742282b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9f350ce",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "283fc20a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db700c35",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cb0c386",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec4cff75",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e755f418",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1aef6e63",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53a6d270",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8910ce66",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1648004d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd4c2e4b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5be2d2d9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9737c11c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "477c08d5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
